{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEHVzFHCvkdg"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook presents how to train CIFAR-10 dataset on the pretrained VGG19 model. I borrow VGG19 included in tensornets package whose github repo is [here](https://github.com/taehoonlee/tensornets). Also, I will try with the different [implementation](https://github.com/machrisaa/tensorflow-vgg) of the same VGG19 architecture after done with tensornets package. \n",
    "\n",
    "The main purpose is to understand the concept of transfer learning and experience with the actual usage. I previously made an notebook to build classical CNN model to train CIFAR-10 dataset, so I can compare between the state of the art CNN model and the very basic CNN model. I am expecting VGG19 will outperform easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Dependency\n",
    "\n",
    "Before diving in, let's install required packages. If your system doesn't have these listed below, please run the code cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "W06VSAiWwNW2"
   },
   "outputs": [],
   "source": [
    "from os.path import isfile, isdir\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensornets as nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU configuration for Tensorflow\n",
    "\n",
    "If you have a very high-end GPU running on your machine, you can skip this section. I needed this configuration, and I have run the training with NVIDIA GTX 1080Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "# # \"Best-fit with coalescing\" algorithm for memory allocation\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Dataset Preparation\n",
    "\n",
    "This is the same step as described in my other github [repo](https://github.com/deep-diver/CIFAR10-img-classification-tensorflow). If you are more interested in this step, please read the detailed explanation from the link. Otherwise, you can skip to the next section.\n",
    "\n",
    "## Download CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16122.0,
     "status": "ok",
     "timestamp": 1.526728322562E12,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540.0
    },
    "id": "yuLcGSrRwelh",
    "outputId": "012a8faf-9f47-4865-8279-f05213c7b358"
   },
   "outputs": [],
   "source": [
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder_path = 'train_1'\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "if not isdir(dataset_folder_path):\n",
    "    with ZipFile('train_1.zip') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "def load_batches(dataset_folder_path, batch_size):\n",
    "    i=0;\n",
    "    ct=0;\n",
    "    X=np.zeros(( batch_size , 224,224,3 ));\n",
    "    no_files=0;\n",
    "    \n",
    "    for filename in os.listdir(dataset_folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "            no_files+=1\n",
    "    print(no_files)        \n",
    "    for filename in os.listdir(dataset_folder_path):\n",
    "        \n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "            img=io.imread(dataset_folder_path+\"/\"+filename)\n",
    "            print(\"Image\",filename,img.shape)\n",
    "            img = skimage.transform.resize(img, (224, 224,3), mode='constant')\n",
    "            X[i,:]=img\n",
    "#             print(\"X\",i,X[0:5])\n",
    "            i+=1\n",
    "#           print(\"Transforemed Image\",img)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if i==batch_size:\n",
    "            i=0\n",
    "            ct+=1\n",
    "            yield X\n",
    "            X=np.zeros(( min(batch_size, no_files - ct*batch_size) , 224,224,3 ));\n",
    "\n",
    "    yield X\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load raw data and reshape the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "9hAxLUckxBwR"
   },
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    print(features)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding method for label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "hipGIs1BxJiK"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the modified input(feature) and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "xz29Y5E8xJe6"
   },
   "outputs": [],
   "source": [
    "def _preprocess_and_save(one_hot_encode, features, labels, filename):\n",
    "    labels = one_hot_encode(labels)\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "  \n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_testing.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def my_preprocess_and_save( batches, filename):\n",
    "    pickle.dump((batches), open(filename, 'wb'))\n",
    "\n",
    "def my_preprocess_and_save_data(dataset_folder_path,batch_size):\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "    no_files=0\n",
    "    print(os.getcwd())\n",
    "    for filename in os.listdir(dataset_folder_path):\n",
    "        #print(filename)\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "            no_files+=1\n",
    "            \n",
    "    n_batches= int(no_files/batch_size);\n",
    "    print(\"NO bathces\",n_batches)\n",
    "    batches = load_batches(dataset_folder_path,batch_size);\n",
    "    \n",
    "    i=0;\n",
    "    for batch_i in batches:\n",
    "        print(\"batches\",i,batch_i.shape,batch_i[0:5])\n",
    "        i+=1\n",
    "        \n",
    "#     my_preprocess_and_save(batches,'bathces.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd())\n",
    "# os.chdir('/home/joohi/temp/proj/ML_Project/CIFAR10-VGG19-Tensorflow-master')\n",
    "# print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "onL8b7jZxjGq",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sameer/ML---CSL-603/Project/CIFAR10-VGG19-Tensorflow-master\n",
      "NO bathces 1\n",
      "79\n",
      "Image 139.jpg (1976, 1683, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sameer/.local/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 143.jpg (688, 1088, 3)\n",
      "Image 176.jpg (800, 612, 3)\n",
      "Image 165.jpg (754, 1000, 3)\n",
      "Image 198.jpg (796, 537, 3)\n",
      "Image 118.jpg (700, 1000, 3)\n",
      "Image 187.jpg (400, 510, 3)\n",
      "Image 178.jpg (453, 570, 3)\n",
      "Image 140.jpg (600, 469, 3)\n",
      "Image 113.jpg (1126, 900, 3)\n",
      "Image 124.jpg (1080, 831, 3)\n",
      "Image 182.jpg (3169, 2536, 3)\n",
      "Image 111.jpg (612, 775, 3)\n",
      "Image 145.jpg (1500, 1139, 3)\n",
      "Image 164.jpg (1500, 2020, 3)\n",
      "Image 196.jpg (425, 387, 4)\n",
      "Image 159.jpg (357, 537, 3)\n",
      "Image 134.jpg (760, 948, 3)\n",
      "Image 153.jpg (2296, 2024, 3)\n",
      "Image 105.jpg (454, 600, 3)\n",
      "Image 106.jpg (1981, 2707, 3)\n",
      "Image 181.jpg (501, 389, 3)\n",
      "Image 17.jpg (650, 753, 3)\n",
      "Image 170.jpg (1628, 2257, 3)\n",
      "Image 138.jpg (2148, 1386, 3)\n",
      "Image 102.jpg (709, 524, 3)\n",
      "Image 16.jpg (770, 1065, 3)\n",
      "Image 160.jpg (500, 333, 3)\n",
      "Image 185.jpg (500, 398, 3)\n",
      "Image 108.jpg (1000, 776, 3)\n",
      "Image 129.jpg (890, 1060, 3)\n",
      "Image 121.jpg (754, 621, 3)\n",
      "Image 179.jpg (976, 1226, 3)\n",
      "Image 10.jpg (561, 597, 3)\n",
      "Image 120.jpg (1034, 516, 3)\n",
      "Image 163.jpg (499, 1024, 3)\n",
      "Image 122.jpg (464, 591, 3)\n",
      "Image 147.jpg (807, 980, 3)\n",
      "Image 197.jpg (550, 706, 3)\n",
      "Image 1.jpg (768, 710, 3)\n",
      "Image 189.jpg (1200, 433, 3)\n",
      "Image 156.jpg (709, 1128, 3)\n",
      "Image 192.jpg (474, 640, 3)\n",
      "Image 126.jpg (1045, 746, 3)\n",
      "Image 195.jpg (1201, 1704)\n",
      "Image 104.jpg (1010, 822, 3)\n",
      "Image 109.jpg (944, 717, 3)\n",
      "Image 180.jpg (450, 338, 3)\n",
      "Image 100.jpg (600, 750, 3)\n",
      "Image 175.jpg (607, 432, 3)\n",
      "Image 135.jpg (1106, 1685, 3)\n",
      "Image 144.jpg (500, 330, 3)\n",
      "Image 141.jpg (1632, 2272, 3)\n",
      "Image 19.jpg (384, 512, 3)\n",
      "Image 151.jpg (512, 800, 3)\n",
      "Image 14.jpg (661, 1035, 3)\n",
      "Image 125.jpg (570, 469, 3)\n",
      "Image 101.jpg (1200, 935, 3)\n",
      "Image 191.jpg (800, 533, 3)\n",
      "Image 150.jpg (396, 570, 3)\n",
      "Image 152.jpg (1000, 794, 3)\n",
      "Image 162.jpg (462, 650, 3)\n",
      "Image 174.jpg (350, 700, 3)\n",
      "Image 173.jpg (432, 550, 3)\n",
      "batches 0 (64, 224, 224, 3) [[[[0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   ...\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]]\n",
      "\n",
      "  [[0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   ...\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]]\n",
      "\n",
      "  [[0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   ...\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.08235294 0.11764706 0.14509804]\n",
      "   [0.08235294 0.11764706 0.14509804]\n",
      "   [0.08235294 0.11764706 0.14509804]\n",
      "   ...\n",
      "   [0.05542717 0.09072129 0.11817227]\n",
      "   [0.05316705 0.08846117 0.11591215]\n",
      "   [0.07058824 0.10588235 0.13333333]]\n",
      "\n",
      "  [[0.08235294 0.11764706 0.14509804]\n",
      "   [0.08235294 0.11764706 0.14509804]\n",
      "   [0.08235294 0.11764706 0.14509804]\n",
      "   ...\n",
      "   [0.07496467 0.11025879 0.13770977]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]]\n",
      "\n",
      "  [[0.08235294 0.11764706 0.14509804]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   ...\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]\n",
      "   [0.06666667 0.10196078 0.12941176]]]\n",
      "\n",
      "\n",
      " [[[0.36876751 0.34915966 0.27072829]\n",
      "   [0.38736495 0.3677571  0.28932573]\n",
      "   [0.38431373 0.36470588 0.28627451]\n",
      "   ...\n",
      "   [0.45910364 0.44733894 0.31792717]\n",
      "   [0.45910364 0.44733894 0.31792717]\n",
      "   [0.45434174 0.44257703 0.31316527]]\n",
      "\n",
      "  [[0.36064426 0.34103641 0.26260504]\n",
      "   [0.37913165 0.35952381 0.28109244]\n",
      "   [0.38431373 0.36470588 0.28627451]\n",
      "   ...\n",
      "   [0.47241897 0.46065426 0.3312425 ]\n",
      "   [0.47291917 0.46115446 0.3317427 ]\n",
      "   [0.44327731 0.43151261 0.30210084]]\n",
      "\n",
      "  [[0.35597239 0.33636455 0.25793317]\n",
      "   [0.37115846 0.35155062 0.27311925]\n",
      "   [0.38546419 0.36585634 0.28742497]\n",
      "   ...\n",
      "   [0.45515206 0.44338735 0.31397559]\n",
      "   [0.45028011 0.43851541 0.30910364]\n",
      "   [0.45672269 0.44495798 0.31554622]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.27618047 0.1977491  0.16105442]\n",
      "   [0.28320328 0.20477191 0.16807723]\n",
      "   [0.27698079 0.19854942 0.16185474]\n",
      "   ...\n",
      "   [0.16723689 0.20253101 0.19076631]\n",
      "   [0.10567227 0.14096639 0.12920168]\n",
      "   [0.10835334 0.14364746 0.13188275]]\n",
      "\n",
      "  [[0.25602241 0.17408964 0.15364146]\n",
      "   [0.29411765 0.21218487 0.19173669]\n",
      "   [0.28529412 0.20336134 0.18291317]\n",
      "   ...\n",
      "   [0.05871349 0.0940076  0.0822429 ]\n",
      "   [0.19352741 0.22882153 0.21705682]\n",
      "   [0.18098239 0.21627651 0.2045118 ]]\n",
      "\n",
      "  [[0.25797319 0.17562025 0.16357543]\n",
      "   [0.27436975 0.19201681 0.17997199]\n",
      "   [0.28282313 0.20047019 0.18842537]\n",
      "   ...\n",
      "   [0.08870548 0.1239996  0.11223489]\n",
      "   [0.12404962 0.15934374 0.14757903]\n",
      "   [0.14091637 0.17621048 0.16444578]]]\n",
      "\n",
      "\n",
      " [[[0.56435574 0.52570028 0.46605642]\n",
      "   [0.6162415  0.57758603 0.51429072]\n",
      "   [0.62072829 0.57254902 0.50943377]\n",
      "   ...\n",
      "   [0.67484494 0.6042567  0.51013906]\n",
      "   [0.67566026 0.60552221 0.5307623 ]\n",
      "   [0.68545418 0.61598639 0.57004802]]\n",
      "\n",
      "  [[0.63248299 0.56637655 0.50419168]\n",
      "   [0.65413665 0.58130752 0.52192377]\n",
      "   [0.63137255 0.55798319 0.4915066 ]\n",
      "   ...\n",
      "   [0.7032563  0.62482493 0.52678571]\n",
      "   [0.69266707 0.62031313 0.51079432]\n",
      "   [0.70532213 0.64201681 0.51540616]]\n",
      "\n",
      "  [[0.66087435 0.56731693 0.49336735]\n",
      "   [0.67204382 0.57580532 0.49917467]\n",
      "   [0.66945778 0.57030812 0.48907063]\n",
      "   ...\n",
      "   [0.73669468 0.64929972 0.5372549 ]\n",
      "   [0.74007103 0.65470188 0.54333233]\n",
      "   [0.75623249 0.67387955 0.56351541]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.67121849 0.38494398 0.24768908]\n",
      "   [0.68392857 0.40469188 0.26845238]\n",
      "   [0.68403361 0.40952381 0.27619048]\n",
      "   ...\n",
      "   [0.52605042 0.27507003 0.17703081]\n",
      "   [0.5252451  0.27831633 0.17757603]\n",
      "   [0.51820728 0.27731092 0.17254902]]\n",
      "\n",
      "  [[0.67436475 0.3920118  0.2429922 ]\n",
      "   [0.67002801 0.39101641 0.2507403 ]\n",
      "   [0.68626451 0.4117547  0.27057823]\n",
      "   ...\n",
      "   [0.53070728 0.29709384 0.19457283]\n",
      "   [0.52177371 0.29243697 0.18901561]\n",
      "   [0.52366447 0.30069528 0.19593337]]\n",
      "\n",
      "  [[0.66465086 0.38229792 0.23327831]\n",
      "   [0.67618547 0.40087035 0.2495048 ]\n",
      "   [0.67732593 0.40281613 0.26163966]\n",
      "   ...\n",
      "   [0.5534964  0.33184274 0.22596038]\n",
      "   [0.55416166 0.33657963 0.23880052]\n",
      "   [0.54065126 0.32608543 0.24037115]]]\n",
      "\n",
      "\n",
      " [[[0.66297519 0.58454382 0.44728892]\n",
      "   [0.68089517 0.6024638  0.47305203]\n",
      "   [0.67154487 0.58919193 0.4676233 ]\n",
      "   ...\n",
      "   [0.81293017 0.76865809 0.7107593 ]\n",
      "   [0.81381021 0.77459453 0.7275357 ]\n",
      "   [0.78319265 0.77142795 0.69796919]]\n",
      "\n",
      "  [[0.71570941 0.6294349  0.48433686]\n",
      "   [0.67592318 0.5857271  0.45239377]\n",
      "   [0.66609019 0.57589411 0.45157219]\n",
      "   ...\n",
      "   [0.68373912 0.61380333 0.50718913]\n",
      "   [0.74601935 0.70945628 0.64674901]\n",
      "   [0.74788009 0.73611538 0.6706023 ]]\n",
      "\n",
      "  [[0.73914097 0.64568859 0.49633635]\n",
      "   [0.67863333 0.58511561 0.44380252]\n",
      "   [0.66232681 0.56854179 0.43587372]\n",
      "   ...\n",
      "   [0.70957227 0.60827675 0.47135448]\n",
      "   [0.72213604 0.66025817 0.57139262]\n",
      "   [0.8100412  0.78005171 0.70701406]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.76971007 0.65990615 0.5030434 ]\n",
      "   [0.68070353 0.56164653 0.41262693]\n",
      "   [0.59104017 0.45925714 0.32200224]\n",
      "   ...\n",
      "   [0.6679972  0.46788434 0.29485294]\n",
      "   [0.60861782 0.43992503 0.30293742]\n",
      "   [0.4471945  0.30706845 0.21697429]]\n",
      "\n",
      "  [[0.84632509 0.74355617 0.58434843]\n",
      "   [0.85159939 0.74025485 0.58808398]\n",
      "   [0.7401026  0.61249062 0.47463579]\n",
      "   ...\n",
      "   [0.62683949 0.43572023 0.28578556]\n",
      "   [0.59592087 0.41448673 0.28465199]\n",
      "   [0.43742059 0.28948923 0.18868204]]\n",
      "\n",
      "  [[0.84835684 0.75907082 0.58163828]\n",
      "   [0.88001013 0.77535514 0.5845979 ]\n",
      "   [0.8361504  0.71176002 0.5358162 ]\n",
      "   ...\n",
      "   [0.62711366 0.44498518 0.29601497]\n",
      "   [0.61326281 0.42416873 0.27747943]\n",
      "   [0.50861313 0.35136523 0.22927108]]]\n",
      "\n",
      "\n",
      " [[[0.1728761  0.1611114  0.13366042]\n",
      "   [0.17244484 0.16068013 0.13322915]\n",
      "   [0.17755602 0.16579132 0.13834034]\n",
      "   ...\n",
      "   [0.13081084 0.12688927 0.10728143]\n",
      "   [0.13295693 0.12903536 0.10942752]\n",
      "   [0.12908468 0.12516311 0.10555527]]\n",
      "\n",
      "  [[0.17188375 0.16011905 0.13266807]\n",
      "   [0.17359069 0.16182598 0.134375  ]\n",
      "   [0.1816525  0.1698878  0.14243682]\n",
      "   ...\n",
      "   [0.13328972 0.12936815 0.10976031]\n",
      "   [0.13266807 0.1287465  0.10913866]\n",
      "   [0.12869484 0.12477327 0.10516543]]\n",
      "\n",
      "  [[0.17076909 0.17076909 0.13939654]\n",
      "   [0.17405462 0.17405462 0.14268207]\n",
      "   [0.17448354 0.17448354 0.14311099]\n",
      "   ...\n",
      "   [0.14158523 0.13766366 0.11805582]\n",
      "   [0.13899239 0.13507083 0.11546298]\n",
      "   [0.13438524 0.13046367 0.11085583]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8802113  0.87628973 0.85668189]\n",
      "   [0.88301836 0.87909679 0.85948895]\n",
      "   [0.88505035 0.88112878 0.86152094]\n",
      "   ...\n",
      "   [0.95563858 0.95956015 0.93995231]\n",
      "   [0.95663086 0.96055242 0.94094458]\n",
      "   [0.95175945 0.95568102 0.93607318]]\n",
      "\n",
      "  [[0.87843137 0.8745098  0.85490196]\n",
      "   [0.88206408 0.87814251 0.85853466]\n",
      "   [0.88721559 0.88329402 0.86368618]\n",
      "   ...\n",
      "   [0.95095413 0.9548757  0.93526786]\n",
      "   [0.94607585 0.94999742 0.93038958]\n",
      "   [0.94576331 0.94968487 0.93007703]]\n",
      "\n",
      "  [[0.8745098  0.87058824 0.85098039]\n",
      "   [0.87586746 0.87194589 0.85233804]\n",
      "   [0.8804564  0.87653483 0.85692699]\n",
      "   ...\n",
      "   [0.94865345 0.95257501 0.93296717]\n",
      "   [0.94618347 0.95010504 0.9304972 ]\n",
      "   [0.9473652  0.95128676 0.93167892]]]]\n",
      "Image 12.jpg (659, 1000, 3)\n",
      "Image 136.jpg (871, 1051, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 186.jpg (3258, 4056, 3)\n",
      "Image 119.jpg (698, 1000, 3)\n",
      "Image 168.jpg (500, 301, 3)\n",
      "Image 157.jpg (1958, 1935, 3)\n",
      "Image 155.jpg (944, 734, 3)\n",
      "Image 18.jpg (480, 381, 3)\n",
      "Image 194.jpg (514, 720, 3)\n",
      "Image 11.jpg (779, 1000, 3)\n",
      "Image 130.jpg (426, 570, 3)\n",
      "Image 142.jpg (800, 601, 3)\n",
      "Image 110.jpg (1584, 1240, 3)\n",
      "Image 146.jpg (1024, 805, 3)\n",
      "Image 114.jpg (604, 816, 3)\n",
      "batches 1 (15, 224, 224, 3) [[[[0.07836353 0.1806657  0.1687872 ]\n",
      "   [0.09358743 0.19162665 0.20808323]\n",
      "   [0.06869638 0.15889246 0.18242187]\n",
      "   ...\n",
      "   [0.12264625 0.29519527 0.2912737 ]\n",
      "   [0.1631773  0.32004005 0.31611848]\n",
      "   [0.10890934 0.26969366 0.25400738]]\n",
      "\n",
      "  [[0.0701651  0.14211888 0.14143611]\n",
      "   [0.11301755 0.19691111 0.21701493]\n",
      "   [0.10814279 0.2199647  0.23576681]\n",
      "   ...\n",
      "   [0.19626085 0.3576182  0.36443718]\n",
      "   [0.12809139 0.27029202 0.26995064]\n",
      "   [0.13390341 0.27610404 0.26791951]]\n",
      "\n",
      "  [[0.09317321 0.14538112 0.15020071]\n",
      "   [0.06146771 0.14536127 0.16573942]\n",
      "   [0.18316373 0.31099158 0.32073423]\n",
      "   ...\n",
      "   [0.10096523 0.25037093 0.26194259]\n",
      "   [0.10022196 0.22349752 0.23077168]\n",
      "   [0.12534951 0.24862508 0.25589923]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.06898072 0.0964317  0.06505915]\n",
      "   [0.05878852 0.0862395  0.05486695]\n",
      "   [0.05578653 0.08323751 0.05186496]\n",
      "   ...\n",
      "   [0.09096045 0.15370554 0.11056829]\n",
      "   [0.10411477 0.18760567 0.12821316]\n",
      "   [0.10971435 0.19320525 0.13381274]]\n",
      "\n",
      "  [[0.08219053 0.10964151 0.07826896]\n",
      "   [0.080538   0.10798898 0.07661643]\n",
      "   [0.06110819 0.08855917 0.05718662]\n",
      "   ...\n",
      "   [0.14745742 0.21020252 0.16706526]\n",
      "   [0.11584696 0.21388618 0.13937638]\n",
      "   [0.12871055 0.22674976 0.15223996]]\n",
      "\n",
      "  [[0.09406059 0.12151157 0.09013902]\n",
      "   [0.09078647 0.11823745 0.0868649 ]\n",
      "   [0.07990915 0.10736013 0.07598758]\n",
      "   ...\n",
      "   [0.14321088 0.21779071 0.15637614]\n",
      "   [0.15205801 0.25955101 0.17012524]\n",
      "   [0.21593137 0.34352241 0.24835434]]]\n",
      "\n",
      "\n",
      " [[[0.54484382 0.5213144  0.39582421]\n",
      "   [0.60423064 0.59246593 0.46305417]\n",
      "   [0.64771356 0.65433996 0.52010501]\n",
      "   ...\n",
      "   [0.10670092 0.04395582 0.05572053]\n",
      "   [0.13668862 0.08570823 0.11315921]\n",
      "   [0.15094628 0.08327251 0.11498076]]\n",
      "\n",
      "  [[0.56661729 0.55353956 0.40713725]\n",
      "   [0.59866611 0.59222623 0.44320662]\n",
      "   [0.63304671 0.6342502  0.48462885]\n",
      "   ...\n",
      "   [0.15499174 0.09224664 0.10401135]\n",
      "   [0.10812595 0.04659018 0.05835488]\n",
      "   [0.10636514 0.05930632 0.06714946]]\n",
      "\n",
      "  [[0.53616722 0.53703382 0.39759054]\n",
      "   [0.69613971 0.69613971 0.55669643]\n",
      "   [0.57643217 0.56466747 0.42914576]\n",
      "   ...\n",
      "   [0.20989773 0.14715263 0.15891734]\n",
      "   [0.17917542 0.10027787 0.10246624]\n",
      "   [0.16896442 0.10542717 0.10322346]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.27546796 0.17116999 0.12420529]\n",
      "   [0.25543368 0.15009629 0.04681373]\n",
      "   [0.35063652 0.23009872 0.15770935]\n",
      "   ...\n",
      "   [0.33285515 0.23787091 0.10713737]\n",
      "   [0.23644438 0.16219044 0.03891713]\n",
      "   [0.25878852 0.17524727 0.1287771 ]]\n",
      "\n",
      "  [[0.23968322 0.1298793  0.08342446]\n",
      "   [0.32812297 0.22616218 0.13174692]\n",
      "   [0.21541445 0.10561053 0.0534134 ]\n",
      "   ...\n",
      "   [0.37479287 0.26891051 0.15126345]\n",
      "   [0.32994506 0.27001119 0.0438712 ]\n",
      "   [0.32835529 0.20829181 0.19622163]]\n",
      "\n",
      "  [[0.18687551 0.07707159 0.03061676]\n",
      "   [0.25870008 0.1567393  0.06232403]\n",
      "   [0.26204079 0.15223687 0.10003974]\n",
      "   ...\n",
      "   [0.30554949 0.19966713 0.08202007]\n",
      "   [0.41531706 0.32695832 0.10262404]\n",
      "   [0.49483424 0.34816057 0.31118533]]]\n",
      "\n",
      "\n",
      " [[[0.73607662 0.72697704 0.76783432]\n",
      "   [0.78643082 0.77858769 0.83155325]\n",
      "   [0.7979448  0.77957996 0.84535377]\n",
      "   ...\n",
      "   [0.8244726  0.82055103 0.80537809]\n",
      "   [0.78099052 0.77055635 0.7926852 ]\n",
      "   [0.81984638 0.79730548 0.81150898]]\n",
      "\n",
      "  [[0.77817877 0.77817877 0.82036002]\n",
      "   [0.8175095  0.80966637 0.86456833]\n",
      "   [0.78166485 0.77382172 0.8187797 ]\n",
      "   ...\n",
      "   [0.78787202 0.77208196 0.78204157]\n",
      "   [0.84402511 0.83877301 0.85838085]\n",
      "   [0.77996605 0.75643664 0.80699686]]\n",
      "\n",
      "  [[0.79797575 0.7919968  0.83754721]\n",
      "   [0.77037878 0.7518473  0.80970857]\n",
      "   [0.82705145 0.82204444 0.85297244]\n",
      "   ...\n",
      "   [0.7864699  0.76818915 0.77650466]\n",
      "   [0.81814288 0.81259254 0.82321085]\n",
      "   [0.83512092 0.8508072  0.8625719 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.42347251 0.41955095 0.44609719]\n",
      "   [0.3753342  0.36616053 0.40929778]\n",
      "   [0.34544099 0.32583315 0.35328413]\n",
      "   ...\n",
      "   [0.78461822 0.75511548 0.7361132 ]\n",
      "   [0.80054491 0.80223402 0.79271271]\n",
      "   [0.77299076 0.77124006 0.78524285]]\n",
      "\n",
      "  [[0.42995261 0.44165948 0.45573136]\n",
      "   [0.3265947  0.30660483 0.3590208 ]\n",
      "   [0.42908476 0.3884782  0.44437806]\n",
      "   ...\n",
      "   [0.73517282 0.71742072 0.71966036]\n",
      "   [0.78850665 0.79295499 0.74382409]\n",
      "   [0.8169918  0.81882847 0.82048257]]\n",
      "\n",
      "  [[0.58002889 0.59571516 0.70944065]\n",
      "   [0.50040735 0.53090455 0.57653468]\n",
      "   [0.50308311 0.50770777 0.58916785]\n",
      "   ...\n",
      "   [0.82391988 0.83389887 0.80268951]\n",
      "   [0.76201387 0.76164622 0.75041735]\n",
      "   [0.72442602 0.69043149 0.69090417]]]\n",
      "\n",
      "\n",
      " [[[0.90671362 0.73854135 0.60764212]\n",
      "   [0.90393501 0.75933686 0.58710891]\n",
      "   [0.8619726  0.73301602 0.55661858]\n",
      "   ...\n",
      "   [0.453447   0.3768745  0.35751988]\n",
      "   [0.56591387 0.48752532 0.33929541]\n",
      "   [0.40676427 0.36475653 0.24766   ]]\n",
      "\n",
      "  [[0.87034126 0.73426902 0.61174532]\n",
      "   [0.89747399 0.77403211 0.61393057]\n",
      "   [0.87398053 0.76093781 0.59759748]\n",
      "   ...\n",
      "   [0.65660389 0.58380446 0.363899  ]\n",
      "   [0.72269001 0.60085315 0.42843825]\n",
      "   [0.41130077 0.32375606 0.19147315]]\n",
      "\n",
      "  [[0.94465317 0.83938044 0.72247899]\n",
      "   [0.92995542 0.8319162  0.67428315]\n",
      "   [0.80555816 0.70751895 0.54932567]\n",
      "   ...\n",
      "   [0.60760335 0.48838254 0.439689  ]\n",
      "   [0.64629508 0.54059593 0.38846945]\n",
      "   [0.4361529  0.36163903 0.24466443]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28386792 0.28386792 0.18190714]\n",
      "   [0.32260279 0.29907338 0.20495573]\n",
      "   [0.24688657 0.22853923 0.13183054]\n",
      "   ...\n",
      "   [0.24664241 0.2348777  0.17605417]\n",
      "   [0.21024035 0.1788678  0.13573054]\n",
      "   [0.24088604 0.20951349 0.16637624]]\n",
      "\n",
      "  [[0.28603316 0.28603316 0.18407238]\n",
      "   [0.31364264 0.29011323 0.19599559]\n",
      "   [0.25885979 0.24051245 0.14380377]\n",
      "   ...\n",
      "   [0.2103654  0.19536189 0.14625475]\n",
      "   [0.22303922 0.18842787 0.15176821]\n",
      "   [0.21951249 0.18490115 0.14824148]]\n",
      "\n",
      "  [[0.25579794 0.25579794 0.15383716]\n",
      "   [0.30777092 0.28424151 0.19012386]\n",
      "   [0.28701574 0.2686684  0.17195972]\n",
      "   ...\n",
      "   [0.20074467 0.1850584  0.13799957]\n",
      "   [0.18569865 0.15040454 0.12249837]\n",
      "   [0.19768783 0.16239371 0.13448755]]]\n",
      "\n",
      "\n",
      " [[[0.26875711 0.11519717 0.25532158]\n",
      "   [0.26240973 0.10756029 0.22467065]\n",
      "   [0.26453409 0.09318759 0.22459023]\n",
      "   ...\n",
      "   [0.54539128 0.25186504 0.30893295]\n",
      "   [0.49670868 0.2097049  0.27637156]\n",
      "   [0.4124442  0.21559546 0.3537082 ]]\n",
      "\n",
      "  [[0.21647409 0.1079159  0.30268131]\n",
      "   [0.19815356 0.10215117 0.26389071]\n",
      "   [0.17949219 0.09301635 0.22620853]\n",
      "   ...\n",
      "   [0.48980491 0.2093192  0.25530134]\n",
      "   [0.57166546 0.30825455 0.36918056]\n",
      "   [0.46597952 0.29601825 0.43304283]]\n",
      "\n",
      "  [[0.23549764 0.10063408 0.23101366]\n",
      "   [0.19787563 0.08498556 0.22623151]\n",
      "   [0.16634552 0.0826336  0.20793943]\n",
      "   ...\n",
      "   [0.51475676 0.24132309 0.30754442]\n",
      "   [0.48523886 0.24594056 0.3317588 ]\n",
      "   [0.30621116 0.16603094 0.32564229]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.66334909 0.53411622 0.58766358]\n",
      "   [0.43024827 0.13339297 0.17860754]\n",
      "   [0.35040211 0.13997779 0.15977   ]\n",
      "   ...\n",
      "   [0.44310279 0.20744431 0.21624267]\n",
      "   [0.45541021 0.23736706 0.25114561]\n",
      "   [0.4938638  0.27849265 0.29340861]]\n",
      "\n",
      "  [[0.66447118 0.54489014 0.62683222]\n",
      "   [0.35379081 0.13391489 0.18026578]\n",
      "   [0.24305246 0.09759388 0.18941155]\n",
      "   ...\n",
      "   [0.44599254 0.19730556 0.1993878 ]\n",
      "   [0.45423615 0.21418888 0.23237975]\n",
      "   [0.44083399 0.20280878 0.22847405]]\n",
      "\n",
      "  [[0.61854867 0.52562971 0.60174632]\n",
      "   [0.22863817 0.1006773  0.17271041]\n",
      "   [0.18610163 0.11685049 0.21511675]\n",
      "   ...\n",
      "   [0.40989419 0.1737105  0.20058922]\n",
      "   [0.41825762 0.19637113 0.20339472]\n",
      "   [0.45952053 0.24292389 0.24232865]]]]\n"
     ]
    }
   ],
   "source": [
    "# preprocess_and_save_data(cifar10_dataset_folder_path, one_hot_encode)\n",
    "my_preprocess_and_save_data(dataset_folder_path,64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning the model for CIFAR-10\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "qIGZ-8GexjBF"
   },
   "outputs": [],
   "source": [
    "# valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input (feature) and output (label)\n",
    "\n",
    "<img src=\"https://lihan.me/assets/images/vgg-hero-cover.jpg\"/>\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "__VGG19 Architecture__\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "(borrowed from [vgg19-caltech101-classification](https://lihan.me/2018/01/vgg19-caltech101-classification/))\n",
    "</p>\n",
    "\n",
    "VGG models described in the [original paper](https://arxiv.org/pdf/1409.1556.pdf) are trained with images whose size is 224x224x3. This can not be changed, so the input image for the transfer learning task should have the same image size. For the output, CIFAR-10 contains 10 categorical image data which makes the output size 10 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "ZEr9SKaPxi1z"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 224, 224, 3), name='input_x')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "- You don't need many epochs since this is transfer learning.\n",
    "- you can increase the batch size if you have a very high-end GPU running. 32 is the maximum value I could try with NVIDIA GTX 1080Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "qCivsIqkHGLn"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "epochs = 7\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG19 model, Define loss, train, and accuracy tensor/Operation\n",
    "\n",
    "The first step is to predefined VGG19 model. \n",
    "- if you want to run the model as it is, just pass the input placeholder.\n",
    "- if you want to train on your own image dataset, set is_training=True, and classes=# of class\n",
    "\n",
    "nets.VGG19 returns the final layer of the VGG19 which is softmax. If you know, tensorflow comes with tf.nn.softmax_cross_entropy_with_logits function, and this applies softmax and cross entropy together. However, nets.VGG19 returns the layer already applied with softmax, so we need only cross entropy. That can be achieved by tf.losses.softmax_cross_entropy function.\n",
    "\n",
    "In your choice, you can choose your favorite optimizer. I am going to use Adam optimizer since it is known to work moderate for most of deep learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "XHpQqG9dxivw"
   },
   "outputs": [],
   "source": [
    "logits = nets.VGG19(x, is_training=True, classes=10)\n",
    "model = tf.identity(logits, name='logits')\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, logits)\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print outputs of each layer\n",
    "\n",
    "- nets.VGG19 comes with handy methods, 'print_outputs', and 'get_outputs'. \n",
    "- With 'print_outputs' method, you can print out how this model is constructed. You could compare the actual implementation and the conceptual model. \n",
    "- With 'get_outputs', you can actually access each layer's output. In this way, you could modify the model in your own way like inserting new layer or removing the existing ones.\n",
    "- if you want to know the more compact to way to navigate the layers, you could g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope: vgg19\n",
      "conv1/1/conv/BiasAdd:0 (?, 224, 224, 64)\n",
      "conv1/1/Relu:0 (?, 224, 224, 64)\n",
      "conv1/2/conv/BiasAdd:0 (?, 224, 224, 64)\n",
      "conv1/2/Relu:0 (?, 224, 224, 64)\n",
      "conv1/pool/MaxPool:0 (?, 112, 112, 64)\n",
      "conv2/1/conv/BiasAdd:0 (?, 112, 112, 128)\n",
      "conv2/1/Relu:0 (?, 112, 112, 128)\n",
      "conv2/2/conv/BiasAdd:0 (?, 112, 112, 128)\n",
      "conv2/2/Relu:0 (?, 112, 112, 128)\n",
      "conv2/pool/MaxPool:0 (?, 56, 56, 128)\n",
      "conv3/1/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/1/Relu:0 (?, 56, 56, 256)\n",
      "conv3/2/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/2/Relu:0 (?, 56, 56, 256)\n",
      "conv3/3/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/3/Relu:0 (?, 56, 56, 256)\n",
      "conv3/4/conv/BiasAdd:0 (?, 56, 56, 256)\n",
      "conv3/4/Relu:0 (?, 56, 56, 256)\n",
      "conv3/pool/MaxPool:0 (?, 28, 28, 256)\n",
      "conv4/1/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/1/Relu:0 (?, 28, 28, 512)\n",
      "conv4/2/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/2/Relu:0 (?, 28, 28, 512)\n",
      "conv4/3/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/3/Relu:0 (?, 28, 28, 512)\n",
      "conv4/4/conv/BiasAdd:0 (?, 28, 28, 512)\n",
      "conv4/4/Relu:0 (?, 28, 28, 512)\n",
      "conv4/pool/MaxPool:0 (?, 14, 14, 512)\n",
      "conv5/1/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/1/Relu:0 (?, 14, 14, 512)\n",
      "conv5/2/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/2/Relu:0 (?, 14, 14, 512)\n",
      "conv5/3/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/3/Relu:0 (?, 14, 14, 512)\n",
      "conv5/4/conv/BiasAdd:0 (?, 14, 14, 512)\n",
      "conv5/4/Relu:0 (?, 14, 14, 512)\n",
      "conv5/pool/MaxPool:0 (?, 7, 7, 512)\n",
      "flatten/flatten/Reshape:0 (?, 25088)\n",
      "fc6/BiasAdd:0 (?, 4096)\n",
      "relu6:0 (?, 4096)\n",
      "drop6/dropout/mul:0 (?, 4096)\n",
      "fc7/BiasAdd:0 (?, 4096)\n",
      "relu7:0 (?, 4096)\n",
      "drop7/dropout/mul:0 (?, 4096)\n",
      "logits/BiasAdd:0 (?, 10)\n",
      "probs:0 (?, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'vgg19/conv1/1/conv/BiasAdd:0' shape=(?, 224, 224, 64) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv1/1/Relu:0' shape=(?, 224, 224, 64) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv1/2/conv/BiasAdd:0' shape=(?, 224, 224, 64) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv1/2/Relu:0' shape=(?, 224, 224, 64) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv1/pool/MaxPool:0' shape=(?, 112, 112, 64) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv2/1/conv/BiasAdd:0' shape=(?, 112, 112, 128) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv2/1/Relu:0' shape=(?, 112, 112, 128) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv2/2/conv/BiasAdd:0' shape=(?, 112, 112, 128) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv2/2/Relu:0' shape=(?, 112, 112, 128) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv2/pool/MaxPool:0' shape=(?, 56, 56, 128) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/1/conv/BiasAdd:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/1/Relu:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/2/conv/BiasAdd:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/2/Relu:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/3/conv/BiasAdd:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/3/Relu:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/4/conv/BiasAdd:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/4/Relu:0' shape=(?, 56, 56, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv3/pool/MaxPool:0' shape=(?, 28, 28, 256) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/1/conv/BiasAdd:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/1/Relu:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/2/conv/BiasAdd:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/2/Relu:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/3/conv/BiasAdd:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/3/Relu:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/4/conv/BiasAdd:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/4/Relu:0' shape=(?, 28, 28, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv4/pool/MaxPool:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/1/conv/BiasAdd:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/1/Relu:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/2/conv/BiasAdd:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/2/Relu:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/3/conv/BiasAdd:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/3/Relu:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/4/conv/BiasAdd:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/4/Relu:0' shape=(?, 14, 14, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/conv5/pool/MaxPool:0' shape=(?, 7, 7, 512) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/flatten/flatten/Reshape:0' shape=(?, 25088) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/fc6/BiasAdd:0' shape=(?, 4096) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/relu6:0' shape=(?, 4096) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/drop6/dropout/mul:0' shape=(?, 4096) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/fc7/BiasAdd:0' shape=(?, 4096) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/relu7:0' shape=(?, 4096) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/drop7/dropout/mul:0' shape=(?, 4096) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/logits/BiasAdd:0' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'vgg19/probs:0' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.print_outputs()\n",
    "logits.get_outputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scope: vgg19\n",
      "Total layers: 19\n",
      "Total weights: 114\n",
      "Total parameters: 418,833,630\n"
     ]
    }
   ],
   "source": [
    "logits.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "YjzH1tD5HafW"
   },
   "source": [
    "## Get Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "fXXUD381xioX"
   },
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each CIFAR-10 image is 32x32, and VGG19 takes input image sizes 224x224 which is incompatible. Each CIFAR-10 image should be resized so that it can be fed into the VGG19 model. \n",
    "\n",
    "skimage.transform.resize function does the trick. It takes parameters..\n",
    "- takes a numpy matrix representation of an image\n",
    "- image size to be transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "X0ub-PEPHF7x"
   },
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "    \n",
    "    tmpFeatures = []\n",
    "    \n",
    "    for feature in features:\n",
    "        tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "        tmpFeatures.append(tmpFeature)\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(tmpFeatures, labels, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inputs for validation\n",
    "\n",
    "The same process from load_preprocess_training_batch is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "D3M7KvDKHGDD"
   },
   "outputs": [],
   "source": [
    "# tmpValidFeatures = []\n",
    "\n",
    "# for feature in valid_features:\n",
    "#     tmpValidFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "#     tmpValidFeatures.append(tmpValidFeature)\n",
    "    \n",
    "# tmpValidFeatures = np.array(tmpValidFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,000 images in a batch is huge to be trained. If you have a very high-end GPU card, you can try all images at once, but I will go with batch validation, then calculate the mean of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553.0,
     "status": "ok",
     "timestamp": 1.526729611931E12,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540.0
    },
    "id": "uf4tGgBHJUq0",
    "outputId": "eb99c4e7-d188-43a3-d797-424563b65625"
   },
   "outputs": [],
   "source": [
    "# print(tmpValidFeatures.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "base_uri": "https://localhost:8080/",
     "height": 262.0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651.0,
     "status": "error",
     "timestamp": 1.526729647966E12,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -540.0
    },
    "id": "jclFs6j0HGJV",
    "outputId": "3c7fce73-dc72-44a3-eec1-8923ac9fc0ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "global_variables_initializer ... done ...\n",
      "model.pretrained ... done ... \n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:    \n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('global_variables_initializer ... done ...')\n",
    "    sess.run(logits.pretrained())\n",
    "    print('model.pretrained ... done ... ')    \n",
    "    \n",
    "#     # Training cycle\n",
    "#     print('starting training ... ')\n",
    "#     for epoch in range(epochs):\n",
    "#         # Loop over all batches\n",
    "#         batches=load_batches(batch_i, batch_size)\n",
    "        \n",
    "#         for batch in batches:\n",
    "#             for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "#                 sess.run(train, {x: batch_features, y: batch_labels})\n",
    "                \n",
    "#             print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            \n",
    "#             # calculate the mean accuracy over all validation dataset\n",
    "#             valid_acc = 0\n",
    "#             for batch_valid_features, batch_valid_labels in batch_features_labels(tmpValidFeatures, valid_labels, batch_size):\n",
    "#                 valid_acc += sess.run(accuracy, {x:batch_valid_features, y:batch_valid_labels})\n",
    "            \n",
    "#             tmp_num = tmpValidFeatures.shape[0]/batch_size\n",
    "#             print('Validation Accuracy: {:.6f}'.format(valid_acc/tmp_num))\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model over random sample images\n",
    "\n",
    "## mapping label index to label name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "cw8naOjVxB2c"
   },
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display prediction results (match or not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "elh_ZDAyHGGg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "    label_names = load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "    fig, axs = plt.subplots(10, 2, figsize=(12,24))\n",
    "\n",
    "    margin = 0.05\n",
    "    ind = np.arange(n_classes)\n",
    "    width = (1. - 2. * margin) / n_classes    \n",
    "    \n",
    "    for image_i, (feature, label_id, prediction) in enumerate(zip(features, label_ids, predictions)):\n",
    "        correct_name = label_names[label_id]\n",
    "        pred_name = label_names[np.argmax(prediction)]\n",
    "        \n",
    "        is_match = 'False'        \n",
    "        \n",
    "        if np.argmax(prediction) == label_id:\n",
    "            is_match = 'True'\n",
    "            \n",
    "        predictions_array = []\n",
    "        pred_names = []\n",
    "        \n",
    "        for index, pred_value in enumerate(prediction):\n",
    "            tmp_pred_name = label_names[index]\n",
    "            predictions_array.append({tmp_pred_name : pred_value})\n",
    "            pred_names.append(tmp_pred_name)\n",
    "        \n",
    "        print('[{}] ground truth: {}, predicted result: {} | {}'.format(image_i, correct_name, pred_name, is_match))\n",
    "        print('\\t- {}\\n'.format(predictions_array))\n",
    "        \n",
    "#         print('image_i: ', image_i)\n",
    "#         print('axs: ', axs, ', axs len: ', len(axs))\n",
    "        axs[image_i][0].imshow(feature)\n",
    "        axs[image_i][0].set_title(pred_name)\n",
    "        axs[image_i][0].set_axis_off()\n",
    "        \n",
    "        axs[image_i][1].barh(ind + margin, prediction, width)\n",
    "        axs[image_i][1].set_yticks(ind + margin)\n",
    "        axs[image_i][1].set_yticklabels(pred_names)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = pickle.load(open('preprocess_testing.p', mode='rb'))\n",
    "tmpFeatures = []\n",
    "\n",
    "for feature in test_features:\n",
    "    tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "    tmpFeatures.append(tmpFeature)\n",
    "\n",
    "tmpFeatures = np.asarray(tmpFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "yT3TlbjrHGA8"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import random\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "batch_size = 64\n",
    "n_samples = 10\n",
    "top_n_predictions = 5\n",
    "\n",
    "def test_model(tmpFeatures):\n",
    "    loaded_graph = tf.Graph()\n",
    "    \n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        loaded_x = loaded_graph.get_tensor_by_name('input_x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('output_y:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in batch_features_labels(tmpFeatures, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        \n",
    "        tmpTestFeatures = []\n",
    "    \n",
    "        for feature in random_test_features:\n",
    "            tmpFeature = skimage.transform.resize(feature, (224, 224), mode='constant')\n",
    "            tmpTestFeatures.append(tmpFeature)\n",
    "           \n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.softmax(loaded_logits),\n",
    "            feed_dict={loaded_x: tmpTestFeatures, loaded_y: random_test_labels})\n",
    "        \n",
    "        display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "test_model(tmpFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    },
    "colab_type": "code",
    "id": "dFqUGLUixBkz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "안녕하세요, Colaboratory입니다의 사본",
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/welcome.ipynb",
     "timestamp": 1.526729659664E12
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
